---
title: "TSS Reference Benchmarks V2"
author: "S. Berzins, A. Thompson"
date: "2025-12-09"
output: html_document
---

#### This script explores the creation of a site-specific reference benchmark for total suspended solids (TSS) for ESM 566 Fall Environmental Statistics final project.

V2 = cleaned up code from the class version.  SYB note 1/6/26 - I verified that this script produces the same output that the class script did, but in order to get the same model run, you have to re-order the input data table for random forest so the rows and columns are in the same order as the class script version (I haven't saved that re-ordering here as the order in the original script is somewhat arbitrary. Instead I have ordered rows and columns alphabetically and by type).

1/23/26 Updated model with new and improved variable selection process and updated data file with outliers removed.

# **1 - LOAD PACKAGES**

```{r warning=FALSE}
library(tidyverse)
library(StreamCatTools) 
library(readxl)
library(writexl)
library(randomForest)
library(vip)
library(caret)
library(ORDEQBioassessment)
library(EnvStats)
library(Metrics)
# devtools::install_github("TravisPritchardODEQ/ORDEQBioassessment", 
#                         host = "https://api.github.com", 
#                        dependencies = TRUE, force = TRUE, upgrade = "never")
```

# **2 - IMPORT DATA**

## STATIONS - *FROM WATER CHEMISTRY BENCHMARKS SCRIPT*

```{r}
tss <- read_excel("~/BioMonORDEQ/Benchmarks/Water Chemistry/TSS v2/TSS_no_outliers2026-01-21.xlsx") #output file from ref benchmarks script - Ambient sites included

comids <- tss %>% 
  select(COMID) # Get just the COMIDs for the next step
```

## WATERSHED PREDICTOR VARIABLES - *FROM EPA STREAMCAT*

#### Learn about StreamCat predictors: <https://www.epa.gov/national-aquatic-resource-surveys/streamcat-metrics-and-definitions>

#### View StreamCat updates: <https://www.epa.gov/national-aquatic-resource-surveys/streamcat-updates>

#### Make table of StreamCat metadata and clean up in Excel

```{r}
# METHOD 1: FIND QUERY-ABLE METRIC NAMES
#partable <- StreamCatTools::sc_get_metric_names()

# METHOD 2: FIND QUERY-ABLE METRIC NAMES (slightly different than above)
#scpar <- StreamCatTools::sc_get_params(param = 'metric_names') 

#metrics_desc <- read_excel("~/BioMonORDEQ/Benchmarks/Water Chemistry/TSS Class Project/StreamCatMetrics_new.xlsx") #final cleaned-up metrics table

# FOR TESTING INDIVIDUAL METRICS/COMIDS (e.g., to ensure names match)
#test <- StreamCatTools::sc_get_data(comid = '23910659', metric = 'precipminusevt', showAreaSqKm = FALSE, aoi='watershed')
#test <- StreamCatTools::sc_get_data(comid = '23910659', metric = 'thalwegdepth', showAreaSqKm = FALSE, aoi='other')
```

#### Run function to query ALL StreamCat data for selected COMIDs by subcategory

```{r}
# NOTE: StreamCat doesn't pull data for 'other' areas of interest when aoi='watershed, catchment, other'. 
# Instead, use aoi='watershed' and run separate line for aoi='other' since they don't pull unless on their own.
# ALSO: Do not separate metric lists onto a new line by hitting the enter button, as any metric after the break will be excluded from the pull.

# FUNCTION - START +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
get_streamcat <- function(comids, type = c("Agriculture","Climate","Dams","Flow","IWI","Land Cover","Lithology","Mining_Toxics","Roads",
                                           "Urban","Wildfire","Others")){
type <- match.arg(type)
#comids_split <- split(comids, ceiling(seq_along(comids)/750)) #removed b/c doesn't seem to be doing anything - wrong data class??

if(type == "Agriculture"){

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'canaldens,pctagdrainage,pctagslphigh2001,pctagslpmid2001,pestic1997,sw_flux,waterinput,wdrw_LD,pctcrop2001,pcthay2001,cbnf,fert,manure,nani,nsurp,agkffact',
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed')) 
  }

if(type == "Climate"){

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'precip2008,precip8110,precip9120,tmax8110,tmax9120,tmean2008,tmean8110,tmean9120,tmin8110,tmin9120,inorgnwetdep2008,nh42008,no32008,sn2008,precip_minus_evt,wetindex', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "Dams"){

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'damdens,damnidstor,damnrmstor,NABD_Dens,NABD_NIDStor,NABD_NrmStor', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "Flow"){

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'bfi,elev,runoff', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "IWI"){

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'chem,conn,habt,hyd,sed,temp', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "Land Cover"){

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'pctbl2001,pctconif2001,pctdecid2001,pctgrs2001,pcthbwet2001,pctice2001,pctmxfst2001,pctow2001,pctshrb2001,pcturbhi2001,pcturblo2001,pcturbmd2001,pcturbop2001,pctwdwet2001,pctfrstloss2002', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "Lithology"){ 

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'al2o3,cao,compstrgth,fe2o3,hydrlcond,k2o,mgo,na2o,p2o5,pctalkintruvol,pctalluvcoast,pctcarbresid,pctcoastcrs,pctcolluvsed,pcteolcrs,pcteolfine,pctextruvol,pctglaclakecrs,pctglaclakefine,pctglactilclay,pctglactilcrs,pctglactilloam,pcthydric,pctnoncarbresid,pctsallake,pctsilicic,pctwater,rockn,s,sio2,clay,kffact,om,perm,Rckdep,rckdep,sand,wtdep,n',
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "Mining_Toxics"){

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'coalminedens,minedens,superfunddens,tridens', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "Roads"){ 

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'rdcrs,rdcrsslpwtd,rddens', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "Urban"){ 

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'huden2010,npdesdens,popden2010,septic,wwtpalldens,wwtpmajordens,wwtpminordens,pctimp2001,pctimpslphigh2001,pctimpslpmid2001,pctnonagintrodmanagveg', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "Wildfire"){ 

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'pctfire2002,pctburnarea2002,pcthighsev2002,pctincvegresp2002,pctlowsev2002,pctmodsev2002,pctnonprocmask2002,pctundsev2002', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "Others"){

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'bankfulldepth,bankfullwidth,ici,iwi,mast2008,msst2008,mwst2008,thalwegdepth,wettedwidth,prg_bmmi0809', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='other')) 
  }

names(streamcat) <- base::toupper(names(streamcat))
return(streamcat)
}
# FUNCTION - END  +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
```

#### Pull ALL StreamCat data by subcategory and merge

```{r}
# PULL DATA BY SUBCATEGORY/TYPE
ag <- get_streamcat(comids = comids, type = "Agriculture")
clim <- get_streamcat(comids = comids, type = "Climate")
dams <- get_streamcat(comids = comids, type = "Dams")
flow <- get_streamcat(comids = comids, type = "Flow")
iwi <- get_streamcat(comids = comids, type = "IWI")
cover <- get_streamcat(comids = comids, type = "Land Cover")
litho <- get_streamcat(comids = comids, type = "Lithology") 
mintox <- get_streamcat(comids = comids, type = "Mining_Toxics")
roads <- get_streamcat(comids = comids, type = "Roads")
urb <- get_streamcat(comids = comids, type = "Urban")
fire <- get_streamcat(comids = comids, type = "Wildfire")
other <- get_streamcat(comids = comids, type = "Others")

# MERGE INTO ONE TABLE
sc_all <- list(ag, clim, dams, flow, iwi, cover, litho, mintox, roads, urb, fire, other)
sc_all <- sc_all %>% reduce(full_join, by = 'COMID')

rm(list=c('ag', 'clim', 'dams', 'flow','iwi', 'cover', 'litho', 'mintox', 'roads', 'urb', 'fire', 'other'))
```

#### Add predictor variables not in StreamCat (LII and III Ecoregion, Lat/Long, erodible vs. resistant geology, slope, stream power) and transform data.

```{r}
# ERODIBLE VS RESISTENT GEOLOGY (KEPT ERODIBLE, SINCE RESISTENT IS INVERSE OF ERODIBLE)
erod_resist_strmpow <- sc_all %>%
  mutate(PCT_EROD = PCTALLUVCOASTWS+PCTCARBRESIDWS+PCTCOASTCRSWS+PCTCOLLUVSEDWS+PCTEOLCRSWS+PCTEOLFINEWS+PCTGLACLAKECRSWS+PCTGLACLAKEFINEWS+PCTGLACTILCLAYWS+PCTGLACTILCRSWS+PCTGLACTILLOAMWS+PCTSALLAKEWS+PCTNONCARBRESIDWS)  %>% 
  mutate(PCT_RESIST = PCTALKINTRUVOLWS+PCTEXTRUVOLWS+PCTHYDRICWS+PCTSILICICWS) 

# SLOPE FROM NHD (TAKES 1-2 MIN)
erod_resist_strmpow <- ORDEQBioassessment::get_NHD_info(erod_resist_strmpow) 

# WATERSHED AREA AND STREAM POWER
erod_resist_strmpow <- erod_resist_strmpow %>% 
  mutate(STRMPOW_CAT = totdasqkm + PRECIP9120WS * slope) %>%  # WSAREASQKM from SC, instead pulling totdasqkm from get_NHD (they are the same)
  select(COMID, PCT_EROD, STRMPOW_CAT, NHD_pSLOPE, SITE_TYPE) # Drop PCT_RESIST since it's the inverse of PCT_ERODE

# JOIN WITH OTHER PARAMETERS NOT FROM SC
tss_vars <- sc_all %>% 
  inner_join(erod_resist_strmpow, by='COMID') %>% 
  inner_join(tss, by = 'COMID')

# RE-ORDER COLUMNS and TRANSFORM DATA
tss_vars <- tss_vars %>% 
  relocate(MLocID:TSS, .before = 'COMID') %>% 
  mutate(logTSS = log(TSS+1)) %>%  # Log transform TSS column
  relocate(logTSS, .after = TSS) %>%  
  relocate(L2Eco:L3Eco, .after = SITE_TYPE) %>% 
  select(-c(HUC8, EcoRegion4)) 
```

#### Explore co-varied metrics and select which we want to retain for modeling purposes.

#### Make Spearman correlation matrix to identify co-varied parameters.

```{r, warning=FALSE}
# FIND OUT WHICH COLUMNS HAVE NAs (AND WRITE CODE FOR THEM BELOW)
sapply(tss_vars, function(x) sum(is.na(x)))

# PERFORM NA ROUGHFIX FUNCTION ON METRICS WITH just a few missing values (wait to see about the ones that are missing a lot: MAST2008, BANKFULLDEPTH, BANKFULLWIDTH, THALWEGDEPTH, WETTEDWIDTH, PRG_BMMI0809)
tss_vars$NANIWS <- na.roughfix(tss_vars$NANIWS) # 1 NA
tss_vars$NSURPWS <- na.roughfix(tss_vars$NSURPWS) # 1 NA
tss_vars$PCTIMPSLPHIGH2001WS <- na.roughfix(tss_vars$PCTIMPSLPHIGH2001WS) # 4 NAs
tss_vars$MWST2008 <- na.roughfix(tss_vars$ MWST2008) # 8 NAs
tss_vars$SW_FLUXWS <- na.roughfix(tss_vars$ SW_FLUXWS) # 2 NAs

# Subset numeric variables only
tss_vars_num <- tss_vars %>% 
  select(!c(SITE_TYPE:L3Eco)) %>% 
  select(!c(MLocID:logTSS)) 

# FULL CORRELATION MATRIX
spear <- cor(tss_vars_num, method = "spearman", use = "pairwise.complete.obs")
spear <- as.data.frame(spear)
spear.rows <- tibble::rownames_to_column(spear)

# CONDENSED CORRELATION MATRIX (>0.8 ONLY)
matrix <- spear.rows %>%  
  gather(-rowname, key = "colname", value = "cor") %>% 
  filter(abs(cor) > 0.8)

#export once, then clean up in Excel
#write_xlsx(matrix, path = "~/BioMonORDEQ/Benchmarks/Water Chemistry/TSS v2/Spearmans2_no_outliers.xlsx")

rm(list=c('spear', 'spear.rows'))
```

##### Use CV, % of sites that have zero values, and KD plots for predictors to help make decisions about which correlated vars to keep/drop:

```{r}
# Look at Coefficient of Variance for predictors.
cv <- tss_vars_num %>% 
  summarise(across(everything(), ~ cv(.x, na.rm = TRUE))) %>% 
  pivot_longer(1:140, names_to="Var", values_to="CV") # Change first argument to 1:# columns

cv_pctzero <- tss_vars_num %>%
  summarise(across(everything(), ~ sum(. == 0, na.rm = TRUE) / n() * 100)) %>% 
  pivot_longer(1:140, names_to="Var", values_to="Percent Zeros") %>%  # Change  first argument to 1:# columns
  inner_join(cv, by = "Var")

#write_xlsx(cv_pctzero, path = "~/BioMonORDEQ/Benchmarks/Water Chemistry/TSS v2/TSS_CofV.xlsx")

rm(cv)
```

```{r}
# Look at KD plots for predictors.
tss_vars %>%
    select("AGKFFACTWS","AL2O3WS","BANKFULLDEPTH","BANKFULLWIDTH","BFIWS","CAOWS","CBNFWS","CLAYWS","CONNWS","DAMDENSWS","DAMNIDSTORWS","DAMNRMSTORWS") %>%  # EDIT THIS LINE to include vars that you want to look at.
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_density() +
  geom_rug()

# If warnings appear with the plot they pertain to NA values being present, ignore them.
```

#### Select variables based on correlation analysis. (Either select desired vars or drop undesired ones. Helps if they are in alphabetical order. Don't get rid of columns you want to keep from AWQMS at this stage.)  SH, AT, and SB did this together and recorded decisions in 'TSSv2 Var selection decisions 1-23-26.xlsx'

```{r}
tss_vars_selected <- tss_vars %>% 
  select(c(MLocID:COMID,BFIWS, CANALDENSWS, CAOWS, CLAYWS, COMPSTRGTHWS, DAMDENSWS, ELEVWS, FE2O3WS, HYDRLCONDWS, KFFACTWS, MINEDENSWS, MSST2008, NHD_pSLOPE, NPDESDENSWS, NWS, OMWS, PCT_EROD, PCTAGDRAINAGEWS, PCTAGSLPMID2001WS, PCTALKINTRUVOLWS, PCTALLUVCOASTWS, PCTBL2001WS, PCTBURNAREA2002WS, PCTCARBRESIDWS, PCTCOLLUVSEDWS, PCTCONIF2001WS, PCTCROP2001WS, PCTDECID2001WS, PCTEOLFINEWS, PCTEXTRUVOLWS, PCTFRSTLOSS2002WS, PCTGLACLAKECRSWS, PCTGLACLAKEFINEWS, PCTGLACTILCRSWS, PCTGRS2001WS, PCTHBWET2001WS, PCTICE2001WS, PCTIMP2001WS, PCTINCVEGRESP2002WS, PCTNONAGINTRODMANAGVEGWS, PCTOW2001WS, PCTSALLAKEWS, PCTSHRB2001WS, PCTURBHI2001WS, PCTURBLO2001WS, PCTURBOP2001WS, PCTWATERWS, PCTWDWET2001WS, PESTIC1997WS, POPDEN2010WS, PRECIP_MINUS_EVTWS, RCKDEPWS, RDCRSSLPWTDWS, RDCRSWS, RDDENSWS, ROCKNWS, SANDWS, SEPTICWS, STRMPOW_CAT, SUPERFUNDDENSWS, SW_FLUXWS, SWS, TMAX9120WS, TRIDENSWS, WATERINPUTWS, WETINDEXWS, WETTEDWIDTH, WTDEPWS, WWTPALLDENSWS, WWTPMAJORDENSWS, SITE_TYPE:L3Eco)) %>% # 74 vars in total
   relocate(COMID, .after = cal_val)
```

#### Perform final correlation check

```{r, warning=FALSE}
# Subset numeric variables only
tss_vars_num_selected <- tss_vars_selected %>% 
  select(!c(SITE_TYPE:L3Eco)) %>% 
  select(!c(MLocID:logTSS)) 

# FULL CORRELATION MATRIX
spear2 <- cor(tss_vars_num_selected, method = "spearman", use = "pairwise.complete.obs")
spear2 <- as.data.frame(spear2)
spear.rows2 <- tibble::rownames_to_column(spear2)

# CONDENSED CORRELATION MATRIX (>0.8 ONLY)
matrix2 <- spear.rows2 %>%  
  gather(-rowname, key = "colname", value = "cor") %>% 
  filter(abs(cor) > 0.8)

rm(list=c('spear2', 'spear.rows2'))
# ***CONTINUE ONCE NO CORRELATED VARIABLES REMAIN***

rm('tss_vars_num_selected')
```

# **3 - PREPARE DATA FOR MODELS**

## HANDLE NA VALUES AND MERGE PREDICTORS WITH TSS DATA

```{r, warning=FALSE}
# FIND OUT WHICH COLUMNS HAVE NAs (AND WRITE CODE FOR THEM BELOW)
sapply(tss_vars_selected, function(x) sum(is.na(x)))

# PERFORM NA ROUGHFIX FUNCTION ON ALL METRICS WITH AT LEAST 1 NA VALUE (ADD CODE AS NEEDED)
tss_vars_selected$WETTEDWIDTH <- na.roughfix(tss_vars_selected$BANKFULLWIDTH) # 63 NAs
```

# **4 - EXPLORE DATA**

## RESPONSE VARIABLE

```{r}
# HISTOGRAM
hist(tss_vars_selected$TSS, main = "", xlab = "TSS") #raw data
hist(tss_vars_selected$logTSS, main = "", xlab = "logTSS") #log-transformed

# DENSITY PLOT
hist(tss_vars_selected$logTSS, main="", prob=T, xlab = "TSS")

# BOX PLOT & STRIP CHART
boxplot(tss_vars_selected$logTSS, ylab = "TSS")
#stripchart(tss_vars_selected$TSS, vertical = T, pch=1, col='red', add = T)

```

# **5 - RANDOM FOREST MODELS**

```{r}
# SUBSET DATA
tss.cal <- tss_vars_selected %>%  #subset CALibration dataset
  filter(cal_val == 'CAL') %>%  
  select(-c(MLocID:TSS, COMID))

tss.val <- tss_vars_selected %>%  #subset VALidation dataset
  filter(cal_val == 'VAL') %>%  
  select(-c(MLocID:TSS, COMID))

tss.ref <- tss_vars_selected %>% #subset reference only dataset
  filter(ReferenceSite == 'REFERENCE') %>%  
  select(-c(MLocID:TSS, COMID))

tss.cal_val <- rbind(tss.cal, tss.val)

#write_xlsx(tss.cal_val, path = paste0("~/BioMonORDEQ/Benchmarks/Water Chemistry/TSS v2/TSS_cal_val", Sys.Date(), ".xlsx"))
```

## FULL MODEL - ALL PREDICTORS INCLUDED 

#### Tuning the model (finding best mtry)

```{r}
# One way to find best mtry based on tuneRF.
    # Tune mtry based on OOB error
best_mtry <- tuneRF(tss.cal[, -which(names(tss.cal) == "logTSS")], # Predictors
                        tss.cal$logTSS, # Response
                        ntreeTry = 500, # Number of trees to try for each mtry
                        stepFactor = 2, # Factor to multiply/divide mtry by
                        improve = 0.01, # Minimum improvement to continue search
                        trace = TRUE, # Print progress
                        plot = TRUE) # Plot OOB error vs. mtry
print(best_mtry)

# Another approach using Caret.  Takes >50 minutes to run, not that different from mtry approach above.
# control <- trainControl(method="repeatedcv", number=10,repeats = 3, search="random")
# set.seed(1)
# mtry <- sqrt(ncol(tss.cal[ , 2:80]
# ))
# rf_random <- train(logTSS ~., data = tss.cal, method = "rf", metric = "RMSE", tuneLength = 15, trControl=control)
# print(rf_random)
# plot(rf_random)

# Going with mtry = 7.

```

#### Build full model

```{r}
set.seed(39)

rf.full <- randomForest(logTSS ~ ., tss.cal, importance = TRUE, mtry=7, keep.forest = TRUE, ntree = 500) #run random forest model on all predictors
#print(rf.full)

varImpPlot(rf.full, type = 1, n.var = 25, main = "All-Sites Model") #variable importance plot
```

#### Tuning the model (how many trees)

```{r}
# How many trees is appropriate?
plot(rf.full, log="x", main = '')  # 500 seems to work fine.
```

#### Model prediction errors - full model

```{r}
# Predictions
pred.rf <- predict(rf.full, newdata = tss.cal)

# Model error 
full.rmse<- rmse(exp(pred.rf)-1, exp(tss.cal$logTSS)-1)

range_tss <- max(exp(tss.cal_val$logTSS)-1) - min(exp(tss.cal_val$logTSS)-1)
full.rmse_scaled <- full.rmse/range_tss

# Percent variance explained
rf.full_pct.var <- round(100 * rf.full$rsq[length(rf.full$rsq)], 2)

# Plot
plot(tss.cal$logTSS ~ pred.rf, xlab = 'predicted logTSS', ylab = 'observed logTSS', main = 'Full model')
abline(a=0,b=1)
text(1.5,4, paste0("RMSE = ",round(full.rmse, 2)," | scaled RMSE = ", round(full.rmse_scaled*100,2), "%"))
text(1,3, paste0("Variance explained = ",rf.full_pct.var,"%"))
```

## REDUCED MODEL - IMPORTANT PREDICTORS ONLY

#### Build reduced model with 20 predictors

```{r}
set.seed(32)

rf.red_20 <- randomForest(logTSS ~ CLAYWS + PRECIP_MINUS_EVTWS + PESTIC1997WS + PCTCONIF2001WS + PCTURBLO2001WS + WATERINPUTWS + PCTAGSLPMID2001WS + SANDWS + SWS + POPDEN2010WS + PCTSHRB2001WS + SW_FLUXWS + RDCRSWS + KFFACTWS + ELEVWS + PCTCROP2001WS + SEPTICWS + ROCKNWS + PCTGLACLAKECRSWS + PCTDECID2001WS, data = tss.cal, importance = TRUE,  keep.forest = TRUE, mtry=7, ntree = 500) 

#print(rf.red_20)
summary(rf.red_20)

varImpPlot(rf.red_20, type = 1, n.var = 20, main = "Reduced Model top 20") #variable importance plot

# Predictions
pred.rf.red_20 <- predict(rf.red_20, newdata = tss.cal)

# Model error 
red_20.rmse<- rmse(exp(pred.rf.red_20)-1, exp(tss.cal$logTSS)-1)
red_20.rmse_scaled <- red_20.rmse/range_tss

# Percent variance explained
rf.red_20_pct.var <- round(100 * rf.red_20$rsq[length(rf.red_20$rsq)], 2)

# Plot
plot(tss.cal$logTSS ~ pred.rf.red_20, xlab = 'predicted logTSS', ylab = 'observed logTSS', main = 'Reduced Model Top 20')
abline(a=0,b=1)
text(1.5,4, paste0("RMSE = ",round(red_20.rmse, 2)," | scaled RMSE = ", round(red_20.rmse_scaled*100,2), "%"))
text(1.5,3.3, paste0("Variance explained = ",rf.red_20_pct.var,"%"))
```

#### Reduced model N = 14

```{r}
set.seed(32)

rf.red_14 <- randomForest(logTSS ~ CLAYWS + PRECIP_MINUS_EVTWS + PESTIC1997WS + PCTCONIF2001WS + PCTURBLO2001WS + WATERINPUTWS + PCTAGSLPMID2001WS + SANDWS + SWS + POPDEN2010WS + PCTSHRB2001WS + SW_FLUXWS + RDCRSWS + KFFACTWS, data = tss.cal, importance = TRUE,  keep.forest = TRUE, mtry=14, ntree = 500) 

#print(rf.red_14)
summary(rf.red_14)

varImpPlot(rf.red_14, type = 1, n.var = 14, main = "Reduced Model Top 14") #variable importance plot

# Predictions
pred.rf.red_14 <- predict(rf.red_14, newdata = tss.cal)

# Model error 
red_14.rmse<- rmse(exp(pred.rf.red_14)-1, exp(tss.cal$logTSS)-1)
red_14.rmse_scaled <- red_14.rmse/range_tss

# Percent variance explained
rf.red_14_pct.var <- round(100 * rf.red_14$rsq[length(rf.red_14$rsq)], 2)

# Plot
plot(tss.cal$logTSS ~ pred.rf.red_14, xlab = 'predicted logTSS', ylab = 'observed logTSS', main = 'Reduced Model Top 14')
abline(a=0,b=1)
text(1.5,4, paste0("RMSE = ",round(red_14.rmse, 2)," | scaled RMSE = ", round(red_14.rmse_scaled*100,2), "%"))
text(1,3.3, paste0("Variance explained = ",rf.red_14_pct.var,"%"))
```
#### Build reduced model with 9 predictors (final reduced model)

```{r}
set.seed(32)

rf.red_9 <- randomForest(logTSS ~ CLAYWS + PRECIP_MINUS_EVTWS + PESTIC1997WS + PCTCONIF2001WS + PCTURBLO2001WS + WATERINPUTWS + PCTAGSLPMID2001WS + SANDWS + SWS , data = tss.cal, importance = TRUE,  keep.forest = TRUE, mtry=9, ntree = 500) 

#print(rf.red_9)
summary(rf.red_9)

varImpPlot(rf.red_9, type = 1, n.var = 9, main = "Reduced Model Top 9") #variable importance plot

# Predictions
pred.rf.red_9 <- predict(rf.red_9, newdata = tss.cal)

# Model error 
red_9.rmse<- rmse(exp(pred.rf.red_9)-1, exp(tss.cal$logTSS)-1)
red_9.rmse_scaled <- red_9.rmse/range_tss

# Percent variance explained
rf.red_9_pct.var <- round(100 * rf.red_9$rsq[length(rf.red_9$rsq)], 2)

# Plot
plot(tss.cal$logTSS ~ pred.rf.red_9, xlab = 'predicted logTSS', ylab = 'observed logTSS', main = 'CAL Reduced Model Top 9')
abline(a=0,b=1)
text(1.2,4, paste0("RMSE = ",round(red_9.rmse, 2)," | scaled RMSE = ", round(red_9.rmse_scaled*100,2), "%"))
text(1.2,3.3, paste0("Variance explained = ",rf.red_9_pct.var,"%"))

#Untransformed plot no log scale axes
plot(exp(tss.cal$logTSS)-1 ~ exp(pred.rf.red_9)-1, xlab = 'predicted TSS', ylab = 'observed TSS', main = 'CAL Reduced Model Top 9 untransformed')
abline(a=0,b=1)
text(15,100, paste0("RMSE = ",round(red_9.rmse, 2)," | scaled RMSE = ", round(red_9.rmse_scaled*100,2), "%"))
text(10,80, paste0("Variance explained = ",rf.red_9_pct.var,"%"))

#Untransformed plot no log scale axes
plot(exp(tss.cal$logTSS) ~ exp(pred.rf.red_9), log = 'xy', xlab = 'predicted TSS (μS/cm)', ylab = 'observed TSS (μS/cm)', main = 'CAL Reduced Model Top 9 log scale axes')
abline(a=0,b=1)
text(3,50, paste0("RMSE = ",round(red_9.rmse, 2)," | scaled RMSE = ", round(red_9.rmse_scaled*100,2), "%"))
text(3,35, paste0("Variance explained = ",rf.red_9_pct.var,"%"))
```
#### Build reduced model with 6 predictors

```{r}
set.seed(32)

rf.red_6 <- randomForest(logTSS ~ CLAYWS + PRECIP_MINUS_EVTWS + PESTIC1997WS + PCTCONIF2001WS + PCTURBLO2001WS + WATERINPUTWS, data = tss.cal, importance = TRUE,  keep.forest = TRUE, mtry=6, ntree = 500) 

#print(rf.red_6)
summary(rf.red_6)

varImpPlot(rf.red_6, type = 1, n.var = 6, main = "Reduced Model Top 6") #variable importance plot

# Predictions
pred.rf.red_6 <- predict(rf.red_6, newdata = tss.cal)

# Model error 
red_6.rmse<- rmse(exp(pred.rf.red_6)-1, exp(tss.cal$logTSS)-1)
red_6.rmse_scaled <- red_6.rmse/range_tss

# Percent variance explained
rf.red_6_pct.var <- round(100 * rf.red_6$rsq[length(rf.red_6$rsq)], 2)

# Plot
plot(tss.cal$logTSS ~ pred.rf.red_6, xlab = 'predicted logTSS', ylab = 'observed logTSS', main = 'Reduced Model Top 6')
abline(a=0,b=1)
text(1.2,4, paste0("RMSE = ",round(red_6.rmse, 2)," | scaled RMSE = ", round(red_6.rmse_scaled*100,2), "%"))
text(1.2,3.3, paste0("Variance explained = ",rf.red_6_pct.var,"%"))
```
#### Residual plot for red_9 model

```{r}
residuals.red_9 <- (exp(tss.cal$logTSS)-1) - (exp(pred.rf.red_9)-1) # Observed minus predicted 
plot(residuals.red_9 ~ (exp(pred.rf.red_9)-1), xlab = "Predicted TSS (mg/L)", ylab = "Residuals", main="rf.red_9 residuals")
abline(h=0, col = "red", lty = 2)
```

#### Test reduced model with VAL data

```{r}
set.seed(32)

rf.red_9_val <- randomForest(logTSS ~ CLAYWS + PRECIP_MINUS_EVTWS + PESTIC1997WS + PCTCONIF2001WS + PCTURBLO2001WS + WATERINPUTWS + PCTAGSLPMID2001WS + SANDWS + SWS , data = tss.val, importance = TRUE,  keep.forest = TRUE, mtry=9, ntree = 500) 

#print(rf.red_9_val)
summary(rf.red_9_val)

varImpPlot(rf.red_9_val, type = 1, n.var = 9, main = "Reduced Model Top 9") #variable importance plot

# Predictions
pred.rf.red_9_val <- predict(rf.red_9_val, newdata = tss.val)

# Model error 
red_9.rmse_val<- rmse(exp(pred.rf.red_9_val)-1, exp(tss.val$logTSS)-1)
red_9.rmse_scaled_val <- red_9.rmse_val/range_tss

# Percent variance explained
rf.red_9_pct.var_val <- round(100 * rf.red_9$rsq[length(rf.red_9$rsq)], 2)

# Plot
plot(tss.val$logTSS ~ pred.rf.red_9_val, xlab = 'predicted logTSS', ylab = 'observed logTSS', main = 'VAL Reduced Model Top 9')
abline(a=0,b=1)
text(1.2,4, paste0("RMSE = ",round(red_9.rmse_val, 2)," | scaled RMSE = ", round(red_9.rmse_scaled_val*100,2), "%"))
text(1.2,3.3, paste0("Variance explained = ",rf.red_9_pct.var,"%"))

#Untransformed plot no log scale axes
plot(exp(tss.val$logTSS)-1 ~ exp(pred.rf.red_9_val)-1, xlab = 'predicted TSS', ylab = 'observed TSS', main = 'VAL Reduced Model Top 9 untransformed')
abline(a=0,b=1)
text(15,80, paste0("RMSE = ",round(red_9.rmse_val, 2)," | scaled RMSE = ", round(red_9.rmse_scaled_val*100,2), "%"))
text(10,70, paste0("Variance explained = ",rf.red_9_pct.var,"%"))

#Untransformed plot no log scale axes
plot(exp(tss.val$logTSS) ~ exp(pred.rf.red_9_val), log = 'xy', xlab = 'predicted TSS (μS/cm)', ylab = 'observed TSS (μS/cm)', main = 'VAL Reduced Model Top 9 log scale axes')
abline(a=0,b=1)
text(3,50, paste0("RMSE = ",round(red_9.rmse_val, 2)," | scaled RMSE = ", round(red_9.rmse_scaled_val*100,2), "%"))
text(3,35, paste0("Variance explained = ",rf.red_9_pct.var_val,"%"))
```
#### Plot Obs vs pred CAL and VAL all sites
 
 SYB 1/23 I think something is wrong with this plot, need to fix.

```{r}
# plot obs vs. predicted CAL 
par(mfrow=c(1,2))
par(mar=c(4.3,5,1,1))
plot(x = exp(pred.rf.red_9) -1, y = exp(tss.cal$logTSS) -1,
	  xlab='Predicted TSS', ylab='Observed TSS', main='red_9 CAL', lwd=1.5, 
	  cex.lab=1.5, las = 1, font = 2)
abline(a=0, b=1, col='blue', lty=2) 

# plot obs vs. predicted VAL
par(new=TRUE)
plot(x = exp(pred.rf.red_9_val) -1 , y = exp(tss.val$logTSS) -1,
	  xlab='', ylab='', main='', pch=2, col='red', cex=1.3, lwd=1.5,axes=FALSE) 
 
# plot residuals CAL
par(mar=c(4.3,4.3,1,1))
plot(x = (exp(pred.rf.red_9)-1), y = exp((tss.cal$logTSS) -1) -(exp(pred.rf.red_9) -1),
	  xlab='Predicted TSS', ylab='Residuals (obs-pred)', main='red_9 VAL', 
	  lwd=1.5,cex.lab=1.5, las = 1, font = 2)
abline(h=0, col="blue", lty = 2)
 
# plot residuals VAL
par(new=TRUE)	
plot(x = (exp(pred.rf.red_9_val) -1), y = (exp(tss.val$logTSS) -1) -(exp(pred.rf.red_9_val) -1),
	  xlab='', ylab="", main="", 
	  pch=2, col='red', 
	  lwd=1.5,cex.lab=1.5, las = 1, font = 2, cex=1.3,
	  axes=FALSE)
```

Predictions on CAL + VAL
```{r}
# Predictions
pred.rf.red_9_cal_val <- predict(rf.red_9, newdata = tss.cal_val)

# Plot
plot(tss.cal_val$logTSS ~ pred.rf.red_9_cal_val, xlab = 'predicted logTSS', ylab = 'observed logTSS', main = 'CAL & VAL Reduced Model Top 9')
abline(a=0,b=1)

#Untransformed plot no log scale axes
plot(exp(tss.cal_val$logTSS) -1 ~ exp(pred.rf.red_9_cal_val)-1, xlab = 'predicted TSS', ylab = 'observed TSS', main = 'CAL & VAL Reduced Model Top 9')
abline(a=0,b=1)

#Untransformed plot no log scale axes
plot(exp(tss.cal_val$logTSS) -1 ~ exp(pred.rf.red_9_cal_val) - 1, log = 'xy', xlab = 'predicted TSS', ylab = 'observed TSS', main = 'CAL & VAL Reduced Model Top 9 log scale axes')
abline(a=0,b=1)

# CALCULATE PROPORTIONS ABOVE 1:1 AND 2:1 LINES
oe <- cbind(pred.rf.red_9_cal_val, tss.cal_val$logTSS)
oe <- as.data.frame(oe) %>% 
  rename(pred_logTSS = V2) %>% 
  mutate(obs_TSS = exp(tss.cal_val$logTSS)) %>% 
  mutate(pred_TSS = exp(pred.rf.red_9_cal_val)-1) %>% 
  mutate('O/E' = obs_TSS/pred_TSS)

print(sum(oe$`O/E`>1)/nrow(tss.cal_val)) # prop above 1:1 line
print(sum(oe$`O/E`>2)/nrow(tss.cal_val)) # prop above 2:1 line
```
## ADJUST HUMAN-INFLUENCED PREDICTORS TO REFERENCE LEVELS

#### Examine reference distributions - Histograms and partial dependence plots

```{r}
# HUMAN INFLUENCED VARS --looking at all reference sites.

# Select only the 4 human influenced predictors from the reduced model.
tss.ref.hi <- tss.ref %>% 
  #filter(cal_val == 'CAL') %>% 
  select(c(PESTIC1997WS, PCTURBLO2001WS, WATERINPUTWS, PCTAGSLPMID2001WS ))

# Mean pesticide use kg/sq km
# Want to scale back to 0 (50th percentile = 0)
par(mfrow=c(1,2))
partialPlot(rf.red_9, as.data.frame(tss.cal_val), PESTIC1997WS, main = '', ylab = "log Predicted TSS")
abline(v=quantile(tss.ref.hi$PESTIC1997WS, probs = c(0.05, 0.25, 0.5, 0.90)), col = c('blue', 'red', 'green', 'black'),lty = 'dashed')
hist(tss.ref.hi$PESTIC1997WS, main = '')
quantile(tss.ref.hi$PESTIC1997WS, probs = seq(.1, .9, by = .1))

# Developed, Low Intensity Land Use Percentage
# Scale back to 0 (50th percentile = 0)
par(mfrow=c(1,2))
partialPlot(rf.red_9, as.data.frame(tss.cal_val), PCTURBLO2001WS, main = '', ylab = "log Predicted TSS")
abline(v=quantile(tss.ref.hi$PCTURBLO2001WS, probs = c(0.05, 0.25, 0.5, 0.90)), col = c('blue', 'red', 'green', 'black'),lty = 'dashed')
hist(tss.ref.hi$PCTURBLO2001WS, main = '')
quantile(tss.ref.hi$PCTURBLO2001WS, probs = seq(.1, .9, by = .1))

# Water Input (km2/cm): Ratio of the total area of irrigated land to precipitation within AOI
# Scale back to 0 (50th percentile = 0)
par(mfrow=c(1,2))
partialPlot(rf.red_9, as.data.frame(tss.cal_val), WATERINPUTWS, main = '', ylab = "log Predicted TSS")
abline(v=quantile(tss.ref.hi$WATERINPUTWS, probs = c(0.05, 0.25, 0.5, 0.90)), col = c('blue', 'red', 'green', 'black'),lty = 'dashed')
hist(tss.ref.hi$WATERINPUTWS, main = '')
quantile(tss.ref.hi$WATERINPUTWS, probs = seq(.1, .9, by = .1))

# Percent landcover ag dominated on >10% slope
# Scale back to 0 (50th percentile = 0)
par(mfrow=c(1,2))
partialPlot(rf.red_9, as.data.frame(tss.cal_val), PCTAGSLPMID2001WS, main = '', ylab = "log Predicted TSS")
abline(v=quantile(tss.ref.hi$PCTAGSLPMID2001WS, probs = c(0.05, 0.25, 0.5, 0.90)), col = c('blue', 'red', 'green', 'black'),lty = 'dashed')
hist(tss.ref.hi$PCTAGSLPMID2001WS, main = '')
quantile(tss.ref.hi$PCTAGSLPMID2001WS, probs = seq(.1, .9, by = .1))

```

#### Reference expectations for environmental variables

```{r}
# Adjust human influenced variables to ref levels

tss.cal_val.refadj <- tss.cal_val %>% 
  select(c('logTSS',CLAYWS, PRECIP_MINUS_EVTWS, PESTIC1997WS, PCTCONIF2001WS, PCTURBLO2001WS, WATERINPUTWS, PCTAGSLPMID2001WS, SANDWS, SWS )) %>% 
  
    mutate(PESTIC1997WS = case_when(
    PESTIC1997WS > 0 ~ 0, # 50th percentile is 0
    TRUE ~ PESTIC1997WS)) %>% 
  
    mutate(PCTURBLO2001WS = case_when(
    PCTURBLO2001WS > 0 ~ 0, # 50th percentile is 0
    TRUE ~ PCTURBLO2001WS)) %>% 
  
    mutate(WATERINPUTWS = case_when(
    WATERINPUTWS > 0 ~ 0, # 50th percentile is 0
    TRUE ~ WATERINPUTWS)) %>% 
    
    mutate(PCTAGSLPMID2001WS = case_when(
    PCTAGSLPMID2001WS > 0 ~ 0, # 50th percentile is 0
    TRUE ~ PCTAGSLPMID2001WS))
```

#### Run reduced model with adjusted human-influenced predictors to get All Sites Ref Expectations

```{r}
# REFERENCE EXPECTATIONS FOR ALL-SITES REDUCED
pred.rf.red_9.all<- predict(rf.red_9, tss.cal_val.refadj) #model prediction on cal+val dataset
plot(tss.cal_val.refadj$logTSS ~ pred.rf.red_9.all, xlab = 'predicted logTSS', ylab = 'observed logTSS', ylim = c(0,6), main = 'red_15 CAL and VAL ref adjusted')

# Model error - NOT REALLY RELEVANT HERE SO OMIT IN PLOTS
#(rmse<-sqrt(sum((pred.rf.red_15.all - tss.cal_val.refadj$logTSS)^2)/length(tss.cal_val.refadj$logTSS)))
ut_pred.rf.red_15.all <- exp(pred.rf.red_15.all)-1
ut_tss.all <- exp(tss.cal_val.refadj$logTSS)-1
RMSE.ut.rf.red_15.all <- sqrt(sum((ut_pred.rf.red_15.all - ut_tss.all)^2)/length(tss.cal_val.refadj$logTSS))
print(paste("inverse natural log RMSE =", RMSE.ut.rf.red_15.all))

RMSE.ut.rf.red_15.all_scaled <- RMSE.ut.rf.red_15.all/range_tss
print(paste("scaled untransformed RMSE", RMSE.ut.rf.red_15.all_scaled*100, '%'))
```

## REFERENCE ONLY MODEL

#### Tuning the model (finding best mtry) --sticking w/ mtry = 7.

```{r}
# One way to find best mtry based on tuneRF.
    # Tune mtry based on OOB error
best_mtry <- tuneRF(tss.ref[, -which(names(tss.ref) == "logTSS")], # Predictors
                        tss.ref$logTSS, # Response
                        ntreeTry = 500, # Number of trees to try for each mtry
                        stepFactor = 1.5, # Factor to multiply/divide mtry by
                        improve = 0.01, # Minimum improvement to continue search
                        trace = TRUE, # Print progress
                        plot = TRUE) # Plot OOB error vs. mtry
print(best_mtry)

# Another approach using Caret.  Takes >50 minutes to run, not that different from mtry approach above.
# control <- trainControl(method="repeatedcv", number=10,repeats = 3, search="random")
# set.seed(1)
# mtry <- sqrt(ncol(tss.cal[ , 2:83]
# ))
# rf_random <- train(log(TSS + 1)~., data = tss.cal, method = "rf", metric = "RMSE", tuneLength = 15, trControl=control)
# print(rf_random)
# plot(rf_random)

```

#### Build reference only model

```{r}
tss.ref <- tss.ref %>% 
  select(c(logTSS,BFIWS, CAOWS, CLAYWS, COMPSTRGTHWS, ELEVWS, FE2O3WS, HYDRLCONDWS, KFFACTWS, MSST2008, NHD_pSLOPE, NWS, OMWS, PCT_EROD, PCTALKINTRUVOLWS, PCTALLUVCOASTWS, PCTBL2001WS, PCTBURNAREA2002WS, PCTCARBRESIDWS, PCTCOLLUVSEDWS, PCTCONIF2001WS, PCTDECID2001WS, PCTEOLFINEWS, PCTEXTRUVOLWS, PCTGLACLAKECRSWS, PCTGLACLAKEFINEWS, PCTGLACTILCRSWS, PCTGRS2001WS, PCTHBWET2001WS, PCTICE2001WS, PCTINCVEGRESP2002WS, PCTOW2001WS, PCTSALLAKEWS, PCTSHRB2001WS, PCTWATERWS, POPDEN2010WS, PRECIP_MINUS_EVTWS, RCKDEPWS, ROCKNWS, SANDWS, STRMPOW_CAT, SW_FLUXWS, SWS, TMAX9120WS, WETINDEXWS, SITE_TYPE, L2Eco, L3Eco))

set.seed(39)
rf.full.ref <- randomForest(logTSS ~ ., tss.ref, importance = TRUE, mtry=7, keep.forest = TRUE, ntree = 500) #run random forest model on all predictors
#print(rf.full.ref)

varImpPlot(rf.full.ref, type = 1, n.var = 20, main = "Reference-Only Model") #variable importance plot

# Model error 
full.rmse.ref<- rmse(exp(pred.rf.full.ref)-1, exp(tss.ref$logTSS)-1)

full.ref.rmse_scaled <- full.rmse.ref/range_tss

# Percent variance explained
rf.full.ref_pct.var <- round(100 * rf.full.ref$rsq[length(rf.full.ref$rsq)], 2)

# Plot
plot(tss.ref$logTSS ~ pred.rf.full.ref, xlab = 'predicted logTSS', ylab = 'observed logTSS', main = 'Full model Reference Only')
abline(a=0,b=1)
text(1.5,4, paste0("RMSE = ",round(full.rmse.ref, 2)," | scaled RMSE = ", round(full.ref.rmse_scaled*100,2), "%"))
text(1,3, paste0("Variance explained = ",rf.full.ref_pct.var,"%"))
```

#### Tuning the model (how many trees)

```{r}
# How many trees is appropriate?
plot(rf.full.ref, log="x")  # 500 seems to work fine.
```

#### Reduce the reference only model

```{r}
set.seed(39)
rf.ref.red_13 <- randomForest(logTSS ~ PCTBL2001WS+ CLAYWS+ ELEVWS+ PRECIP_MINUS_EVTWS+ BFIWS+PCTICE2001WS+WETINDEXWS+SWS+ROCKNWS+SANDWS+FE2O3WS+TMAX9120WS+PCTSHRB2001WS, tss.ref, importance = TRUE, mtry=7, keep.forest = TRUE, ntree = 500) #run random forest model on all predictors
#print(rf.ref.red_13)

varImpPlot(rf.ref.red_13, type = 1, n.var = 13, main = "Full Model Ref only") #variable importance plot

pred.rf.ref.red_13 <- predict(rf.ref.red_13, newdata = tss.ref)

# Model error 
red.ref.red_13_rmse <- rmse(exp(pred.rf.ref.red_13)-1, exp(tss.ref$logTSS)-1)

red.ref.red_13_rmse_scaled <- red.ref.red_13_rmse/range_tss

# Percent variance explained
rf.ref.red_13_pct.var <- round(100 * rf.ref.red_13$rsq[length(rf.ref.red_13$rsq)], 2)

# Plot
plot(tss.ref$logTSS ~ pred.rf.ref.red_13, xlab = 'predicted logTSS', ylab = 'observed logTSS', main = 'Reduced model Reference Only')
abline(a=0,b=1)
text(1.5,4, paste0("RMSE = ",round(red.ref.red_13_rmse, 2)," | scaled RMSE = ", round(red.ref.red_13_rmse_scaled*100,2), "%"))
text(1,3, paste0("Variance explained = ",rf.ref.red_13_pct.var,"%"))

```


#### Run all sites through to get ref expectations

```{r}
tss.cal_val.immutable <- tss.cal_val %>% 
  select(c(logTSS,BFIWS, CAOWS, CLAYWS, COMPSTRGTHWS, ELEVWS, FE2O3WS, HYDRLCONDWS, KFFACTWS, MSST2008, NHD_pSLOPE, NWS, OMWS, PCT_EROD, PCTALKINTRUVOLWS, PCTALLUVCOASTWS, PCTBL2001WS, PCTBURNAREA2002WS, PCTCARBRESIDWS, PCTCOLLUVSEDWS, PCTCONIF2001WS, PCTDECID2001WS, PCTEOLFINEWS, PCTEXTRUVOLWS, PCTGLACLAKECRSWS, PCTGLACLAKEFINEWS, PCTGLACTILCRSWS, PCTGRS2001WS, PCTHBWET2001WS, PCTICE2001WS, PCTINCVEGRESP2002WS, PCTOW2001WS, PCTSALLAKEWS, PCTSHRB2001WS, PCTWATERWS, POPDEN2010WS, PRECIP_MINUS_EVTWS, RCKDEPWS, ROCKNWS, SANDWS, STRMPOW_CAT, SW_FLUXWS, SWS, TMAX9120WS, WETINDEXWS, SITE_TYPE, L2Eco, L3Eco))

pred.rf.ref.red_13_all<- predict(rf.ref.red_13, tss.cal_val.immutable) #model prediction on cal+val dataset

# Model error 
red.ref.red_13_rmse_all <- rmse(exp(pred.rf.ref.red_13_all)-1, exp(tss.cal_val$logTSS)-1)

red.ref.red_13_rmse_scaled_all <- red.ref.red_13_rmse_all/range_tss

# Percent variance explained
rf.ref.red_13_pct.var_all <- round(100 * rf.ref.red_13$rsq[length(rf.ref.red_13$rsq)], 2)

# Plot
plot(tss.cal_val$logTSS ~ pred.rf.ref.red_13_all, xlab = 'predicted logTSS', ylab = 'observed logTSS', main = 'Reduced model Reference Only CAL and VAL')
abline(a=0,b=1)
text(1.5,4, paste0("RMSE = ",round(red.ref.red_13_rmse_all, 2)," | scaled RMSE = ", round(red.ref.red_13_rmse_scaled_all*100,2), "%"))
text(1,3, paste0("Variance explained = ",rf.ref.red_13_pct.var_all,"%"))
```

```{r}
oe.allsites <- cbind(pred.rf.ref.red_13_all, tss.cal_val$logTSS)
oe.allsites <- as.data.frame(oe.allsites) %>% 
  rename(pred_logTSS = V2) %>% 
  mutate(obs_TSS = exp(tss.cal_val$logTSS) -1) %>% 
  mutate(pred_TSS = exp(pred.rf.ref.red_13_all)-1) %>% 
  mutate('O/E' = obs_TSS/pred_TSS)

print(sum(oe.allsites$`O/E`>1)/732) # prop above 1:1 line
print(sum(oe.allsites$`O/E`>2)/732) # prop above 2:1 line
```
