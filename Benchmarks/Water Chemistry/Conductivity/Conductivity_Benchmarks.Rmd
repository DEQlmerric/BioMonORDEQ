---
title: "Conductivity Reference Benchmarks"
author: "S. Berzins, A. Thompson"
date: "2026-01-06"
output: html_document
---

#### Trying the script we created in class for a different parameter (Conductivity)

# **1 - LOAD PACKAGES**

```{r warning=FALSE}
library(tidyverse)
library(StreamCatTools) 
library(readxl)
library(writexl)
library(randomForest)
library(vip)
library(caret)
library(ORDEQBioassessment)
library(EnvStats)
library(Metrics)
# devtools::install_github("TravisPritchardODEQ/ORDEQBioassessment", 
#                         host = "https://api.github.com", 
#                        dependencies = TRUE, force = TRUE, upgrade = "never")
```

# **2 - IMPORT DATA**

## STATIONS/TSS - *FROM WATER CHEMISTRY BENCHMARKS SCRIPT*

```{r}
cond <- read_excel("Conductivity2026-01-06.xlsx") #output file from ref benchmarks script - Ambient sites included

comids <- cond %>% 
  select(COMID) %>%  #get just the COMIDs for next step
  filter(!COMID %in% c("23915259","23810652","23765365","23910789","24505148","23881294","23876327","24506738","23774647","23877125","23872909","23941071")) # REMOVE UNWANTED COMIDS ('used closest COMID') FOR SITES ON HIGH RES NHD
```

## WATERSHED PREDICTOR VARIABLES - *FROM EPA STREAMCAT*

#### Learn about StreamCat predictors: <https://www.epa.gov/national-aquatic-resource-surveys/streamcat-metrics-and-definitions>

#### View StreamCat updates: <https://www.epa.gov/national-aquatic-resource-surveys/streamcat-updates>

#### Make table of StreamCat metadata and clean up in Excel

```{r}
# METHOD 1: FIND QUERY-ABLE METRIC NAMES
#partable <- StreamCatTools::sc_get_metric_names()

# METHOD 2: FIND QUERY-ABLE METRIC NAMES (slightly different than above)
#scpar <- StreamCatTools::sc_get_params(param = 'metric_names') 

#metrics_desc <- read_excel("~/BioMonORDEQ/Benchmarks/Water Chemistry/TSS Class Project/StreamCatMetrics_new.xlsx") #final cleaned-up metrics table

# FOR TESTING INDIVIDUAL METRICS/COMIDS (e.g., to ensure names match)
#test <- StreamCatTools::sc_get_data(comid = '23910659', metric = 'precipminusevt', showAreaSqKm = FALSE, aoi='watershed')
#test <- StreamCatTools::sc_get_data(comid = '23910659', metric = 'thalwegdepth', showAreaSqKm = FALSE, aoi='other')
```

#### Run function to query ALL StreamCat data for selected COMIDs by subcategory

```{r}
# NOTE: StreamCat doesn't pull data for 'other' areas of interest when aoi='watershed, catchment, other'. 
# Instead, use aoi='watershed' and run separate line for aoi='other' since they don't pull unless on their own.
# ALSO: Do not separate metric lists onto a new line by hitting the enter button, as any metric after the break will be excluded from the pull.

# FUNCTION - START +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
get_streamcat <- function(comids, type = c("Agriculture","Climate","Dams","Flow","IWI","Land Cover","Lithology","Mining_Toxics","Roads",
                                           "Urban","Wildfire","Others")){
type <- match.arg(type)

if(type == "Agriculture"){

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'canaldens,pctagdrainage,pctagslphigh2001,pctagslpmid2001,pestic1997,sw_flux,waterinput,wdrw_LD,pctcrop2001,pcthay2001,cbnf,fert,manure,nani,nsurp,agkffact',
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed')) 
  }

if(type == "Climate"){

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'precip2008,precip8110,precip9120,tmax8110,tmax9120,tmean2008,tmean8110,tmean9120,tmin8110,tmin9120,inorgnwetdep2008,nh42008,no32008,sn2008,precip_minus_evt,wetindex', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "Dams"){

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'damdens,damnidstor,damnrmstor,NABD_Dens,NABD_NIDStor,NABD_NrmStor', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "Flow"){

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'bfi,elev,runoff', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "IWI"){

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'chem,conn,habt,hyd,sed,temp', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "Land Cover"){

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'pctbl2001,pctconif2001,pctdecid2001,pctgrs2001,pcthbwet2001,pctice2001,pctmxfst2001,pctow2001,pctshrb2001,pcturbhi2001,pcturblo2001,pcturbmd2001,pcturbop2001,pctwdwet2001,pctfrstloss2002', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "Lithology"){ 

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'al2o3,cao,compstrgth,fe2o3,hydrlcond,k2o,mgo,na2o,p2o5,pctalkintruvol,pctalluvcoast,pctcarbresid,pctcoastcrs,pctcolluvsed,pcteolcrs,pcteolfine,pctextruvol,pctglaclakecrs,pctglaclakefine,pctglactilclay,pctglactilcrs,pctglactilloam,pcthydric,pctnoncarbresid,pctsallake,pctsilicic,pctwater,rockn,s,sio2,clay,kffact,om,perm,Rckdep,rckdep,sand,wtdep,n',
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "Mining_Toxics"){

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'coalminedens,minedens,superfunddens,tridens', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "Roads"){ 

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'rdcrs,rdcrsslpwtd,rddens', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "Urban"){ 

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'huden2010,npdesdens,popden2010,septic,wwtpalldens,wwtpmajordens,wwtpminordens,pctimp2001,pctimpslphigh2001,pctimpslpmid2001,pctnonagintrodmanagveg', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "Wildfire"){ 

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'pctfire2002,pctburnarea2002,pcthighsev2002,pctincvegresp2002,pctlowsev2002,pctmodsev2002,pctnonprocmask2002,pctundsev2002', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='watershed'))
  }

if(type == "Others"){

  streamcat <- purrr::map_dfr(comids, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'bankfulldepth,bankfullwidth,ici,iwi,mast2008,msst2008,mwst2008,thalwegdepth,wettedwidth,prg_bmmi0809', 
                                                                           showAreaSqKm = FALSE,
                                                                           aoi='other')) 
  }

names(streamcat) <- base::toupper(names(streamcat))
return(streamcat)
}
# FUNCTION - END  +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
```

#### Pull ALL StreamCat data by subcategory and merge

```{r}
# PULL DATA BY SUBCATEGORY/TYPE
ag <- get_streamcat(comids = comids, type = "Agriculture")
clim <- get_streamcat(comids = comids, type = "Climate")
dams <- get_streamcat(comids = comids, type = "Dams")
flow <- get_streamcat(comids = comids, type = "Flow")
iwi <- get_streamcat(comids = comids, type = "IWI") 
cover <- get_streamcat(comids = comids, type = "Land Cover")
litho <- get_streamcat(comids = comids, type = "Lithology") 
mintox <- get_streamcat(comids = comids, type = "Mining_Toxics")
roads <- get_streamcat(comids = comids, type = "Roads")
urb <- get_streamcat(comids = comids, type = "Urban")
fire <- get_streamcat(comids = comids, type = "Wildfire")
other <- get_streamcat(comids = comids, type = "Others")

# MERGE INTO ONE TABLE
sc_all <- list(ag, clim, dams, flow, iwi, cover, litho, mintox, roads, urb, fire, other)
sc_all <- sc_all %>% reduce(full_join, by = 'COMID')

rm(list=c('ag', 'clim', 'dams', 'flow','iwi', 'cover', 'litho', 'mintox', 'roads', 'urb', 'fire', 'other'))
```

#### Add predictor variables not in StreamCat (LII and III Ecoregion, Lat/Long, erodible vs. resistant geology, slope, stream power)

```{r}
# ERODIBLE VS RESISTENT GEOLOGY (KEPT ERODIBLE, SINCE RESISTENT IS INVERSE OF ERODIBLE)
erod_resist_strmpow <- sc_all %>%
  mutate(PCT_EROD = PCTALLUVCOASTWS+PCTCARBRESIDWS+PCTCOASTCRSWS+PCTCOLLUVSEDWS+PCTEOLCRSWS+PCTEOLFINEWS+PCTGLACLAKECRSWS+PCTGLACLAKEFINEWS+PCTGLACTILCLAYWS+PCTGLACTILCRSWS+PCTGLACTILLOAMWS+PCTSALLAKEWS+PCTNONCARBRESIDWS)  %>% 
  mutate(PCT_RESIST = PCTALKINTRUVOLWS+PCTEXTRUVOLWS+PCTHYDRICWS+PCTSILICICWS) 

# SLOPE FROM NHD (TAKES 1-2 MIN)
erod_resist_strmpow <- ORDEQBioassessment::get_NHD_info(erod_resist_strmpow) 

# WATERSHED AREA AND STREAM POWER
erod_resist_strmpow <- erod_resist_strmpow %>% 
  mutate(STRMPOW_CAT = totdasqkm + PRECIP9120WS * slope) %>%  # WSAREASQKM from SC, instead pulling totdasqkm from get_NHD (they are the same)
  select(COMID, PCT_EROD, STRMPOW_CAT, NHD_pSLOPE, SITE_TYPE) # Drop PCT_RESIST since it's the inverse of PCT_ERODE

# JOIN WITH OTHER PARAMETERS NOT FROM SC
cond_vars <- sc_all %>% 
  inner_join(erod_resist_strmpow, by='COMID') %>% 
  inner_join(cond, by = 'COMID')

# RE-ORDER COLUMNS 
cond_vars <- cond_vars %>% 
  relocate(MLocID:Conductivity, .before = 'COMID') %>% 
  relocate(L2Eco:L3Eco, .after = SITE_TYPE) %>% 
  select(-c(HUC8, EcoRegion4)) 
```

#### Explore co-varied metrics and select which we want to retain for modeling purposes.

#### Make Spearman correlation matrix to identify co-varied parameters

```{r, warning=FALSE}
# PERFORM NA ROUGHFIX FUNCTION ON METRICS WITH just a few missing values (wait to see about the ones that are missing a lot: BANKFULLDEPTH, BANKFULLWIDTH, MAST2008, THALWEGDEPTH, WETTEDWIDTH)
cond_vars$CLAYWS  <- na.roughfix(cond_vars$CLAYWS ) # 1 NA
cond_vars$MSST2008 <- na.roughfix(cond_vars$ MSST2008) # 1 NA
cond_vars$MWST2008 <- na.roughfix(cond_vars$ MWST2008) # 12 NAs
cond_vars$NANIWS <- na.roughfix(cond_vars$NANIWS) # 1 NA
cond_vars$NSURPWS <- na.roughfix(cond_vars$NSURPWS) # 1 NA
cond_vars$OMWS <- na.roughfix(cond_vars$OMWS) # 1 NA
cond_vars$PCTIMPSLPHIGH2001WS <- na.roughfix(cond_vars$PCTIMPSLPHIGH2001WS) # 4 NAs
cond_vars$PERMWS <- na.roughfix(cond_vars$PERMWS) # 1 NA
cond_vars$RCKDEPWS <- na.roughfix(cond_vars$RCKDEPWS) # 1 NA
cond_vars$SANDWS <- na.roughfix(cond_vars$SANDWS) # 1 NA
cond_vars$SW_FLUXWS <- na.roughfix(cond_vars$SW_FLUXWS) # 1 NA
cond_vars$WTDEPWS <- na.roughfix(cond_vars$WTDEPWS) # 1 NA

# Subset numeric variables only
cond_vars_num <- cond_vars %>% 
  select(!c(SITE_TYPE:L3Eco)) %>% 
  select(!c(MLocID:Conductivity)) %>%  
  relocate(sort(names(.))) # sort columns alphabetically

# FIND OUT WHICH COLUMNS HAVE NAs (AND WRITE CODE FOR THEM BELOW)
sapply(cond_vars_num, function(x) sum(is.na(x)))

# FULL CORRELATION MATRIX
spear <- cor(cond_vars_num, method = "spearman", use = "pairwise.complete.obs")
spear <- as.data.frame(spear)
spear.rows <- tibble::rownames_to_column(spear)

# CONDENSED CORRELATION MATRIX (>0.8 ONLY)
matrix <- spear.rows %>%  
  gather(-rowname, key = "colname", value = "cor") %>% 
  filter(abs(cor) > 0.8)

#export once, then clean up in Excel
#write_xlsx(matrix, path = "~/BioMonORDEQ/Benchmarks/Water Chemistry/Conductivity/Cond_Spearmans_Matrix.xlsx")

rm(list=c('spear', 'spear.rows'))
```

##### NOTE: Take the correlation matrix and make predictor decisions. Look at CV, proportion of 0s, and kernel density plots of variables to help make these decisions.

```{r}
# Look at Coefficient of Variance for predictors.
cv <- cond_vars_num %>% 
  summarise(across(everything(), ~ cv(.x))) %>% 
  pivot_longer(1:139, names_to="Var", values_to="CV") # Change first argument to 1:# columns

cv_pctzero <- cond_vars_num %>%
  summarise(across(everything(), ~ sum(. == 0) / n() * 100)) %>% 
  pivot_longer(1:139, names_to="Var", values_to="Percent Zeros") %>%  # Change  first argument to 1:# columns
  inner_join(cv, by = "Var")

#write_xlsx(cv_pctzero, path = paste0("C://Users//sberzin//OneDrive - Oregon//Desktop//CofV", Sys.Date(), ".xlsx"))

rm(cv)
```
 
```{r}
# Look at KD plots for predictors.
cond_vars %>%
    select("AGKFFACTWS","AL2O3WS","BANKFULLDEPTH","BANKFULLWIDTH","BFIWS","CAOWS","CBNFWS","CLAYWS","CONNWS","DAMDENSWS","DAMNIDSTORWS","DAMNRMSTORWS") %>%  # Edit this line to include different vars
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_density() +
  geom_rug()
```
#### Select variables based on correlation analysis. (Either select desired vars or drop undesired ones. Helps if they are in alphabetical order. Don't get rid of columns you want to keep from AWQMS at this stage.)  SH, AT, and SB did this together and recorded decisions in 'Var selection decision 1-8-26.xlsx'

```{r}
cond_vars_selected <- cond_vars %>% 
  select(c(MLocID:COMID,BFIWS, CANALDENSWS, CAOWS, CLAYWS, COMPSTRGTHWS, DAMDENSWS, ELEVWS, FE2O3WS, HYDRLCONDWS, K2OWS, KFFACTWS, MINEDENSWS, MSST2008, NA2OWS, NHD_pSLOPE, NPDESDENSWS, NWS, OMWS, PCT_EROD, PCTAGDRAINAGEWS, PCTAGSLPMID2001WS, PCTALKINTRUVOLWS, PCTALLUVCOASTWS, PCTBL2001WS, PCTBURNAREA2002WS, PCTCOLLUVSEDWS, PCTCONIF2001WS, PCTCROP2001WS, PCTDECID2001WS, PCTEOLCRSWS, PCTEOLFINEWS, PCTEXTRUVOLWS, PCTFRSTLOSS2002WS, PCTGLACLAKECRSWS, PCTGLACLAKEFINEWS, PCTGLACTILCRSWS, PCTGRS2001WS, PCTHBWET2001WS, PCTICE2001WS, PCTIMP2001WS, PCTINCVEGRESP2002WS, PCTNONAGINTRODMANAGVEGWS, PCTOW2001WS, PCTSALLAKEWS, PCTSHRB2001WS, PCTURBHI2001WS, PCTURBLO2001WS, PCTURBOP2001WS, PCTWATERWS, PESTIC1997WS, POPDEN2010WS, PRECIP9120WS, RCKDEPWS, RDCRSSLPWTDWS, RDCRSWS, RDDENSWS, ROCKNWS, SANDWS, SEPTICWS, STRMPOW_CAT, SUPERFUNDDENSWS, SW_FLUXWS, SWS, TMAX9120WS, TRIDENSWS, WATERINPUTWS, WETINDEXWS, WETTEDWIDTH, WTDEPWS, WWTPALLDENSWS,SITE_TYPE:L3Eco)) %>% 
  relocate(COMID, .after = cal_val) %>% 
  mutate(logCond = log(Conductivity)) %>% 
  relocate(logCond, .before= Conductivity)
```

#### Perform final correlation check

```{r, warning=FALSE}
# Subset numeric variables only
cond_vars_num_selected <- cond_vars_selected %>% 
  select(!c(SITE_TYPE:L3Eco)) %>% 
  select(!c(MLocID:Conductivity)) 

# FULL CORRELATION MATRIX
spear2 <- cor(cond_vars_num_selected, method = "spearman", use = "pairwise.complete.obs")
spear2 <- as.data.frame(spear2)
spear2.rows <- tibble::rownames_to_column(spear2)

# CONDENSED CORRELATION MATRIX (>0.8 ONLY)
matrix2 <- spear2.rows %>%  
  gather(-rowname, key = "colname", value = "cor") %>% 
  filter(abs(cor) > 0.8)

rm(list=c('spear2', 'spear2.rows', 'cond_vars_num_selected'))

# ***CONTINUE ONCE NO CORRELATED VARIABLES REMAIN***

rm('cond_vars_num_selected')
```

# **3 - PREPARE DATA FOR MODELS**

## HANDLE NA VALUES AND TRANSFORM DATA

```{r, warning=FALSE}
# FIND OUT WHICH COLUMNS HAVE NAs (AND WRITE CODE FOR THEM BELOW)
sapply(cond_vars_selected, function(x) sum(is.na(x)))

# PERFORM NA ROUGHFIX FUNCTION ON ALL REMAINING METRICS.
cond_vars_selected$WETTEDWIDTH <- na.roughfix(cond_vars_selected$WETTEDWIDTH) # 70 NAs
```

# **4 - EXPLORE DATA**

## RESPONSE VARIABLE

```{r}
# HISTOGRAM
hist(cond_vars_selected$Conductivity, main = "", xlab = "Conductivity") #raw data
hist(cond_vars_selected$logCond, main = "", xlab = "log(Conductivity)")

# DENSITY PLOT
hist(cond_vars_selected$logCond, main="", prob=T, xlab = "logCond")
d <- density(cond_vars_selected$logCond) #Estimate probability density and save it into **d**
lines(d, col='red',lwd=2) #Superimpose the probability density as a curve on the previous probability density histogram

# BOX PLOT & STRIP CHART
boxplot(cond_vars_selected$logCond, ylab = "logCond")
#stripchart(tss_vars_selected$TSS, vertical = T, pch=1, col='red', add = T)

```

## PREDICTOR VARIABLES

```{r}
# Kernel density plot function
kd_plots <- function(data, filter_col_name, filter_value) {
  data %>%
    filter(.data[[filter_col_name]] == filter_value) %>% # Using .data[[]] for dynamic column names
    select(PRECIP9120WS,TMAX9120WS,KFFACTWS,MSST2008,OMWS,CLAYWS,SWS,PCT_EROD,ELEVWS,SW_FLUXWS,POPDEN2010WS,NA2OWS,ROCKNWS,SANDWS,COMPSTRGTHWS,WTDEPWS,RDCRSWS,CAOWS,BFIWS,PCTDECID2001WS) %>% 
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_density() +
  geom_rug() + ggtitle(paste0(filter_value))
}

# Top 20 variables from RF model broken out by reference status
kd_plots(data = cond_vars_selected, "ReferenceSite", "REFERENCE")
kd_plots(data = cond_vars_selected, "ReferenceSite", "MODERATELY DISTURBED")
kd_plots(data = cond_vars_selected, "ReferenceSite", "MOST DISTURBED")

# Top 20 variables from RF model broken out by L2 Ecoregion
kd_plots(data = cond_vars_selected, "L2Eco", "Western Cordillera")
kd_plots(data = cond_vars_selected, "L2Eco", "Cold Deserts")
kd_plots(data = cond_vars_selected, "L2Eco", "Marine West Coast Forest")

# Top 20 variables from RF model broken out by Conductivity category 
# < 100
cond_vars_selected %>%
  filter(Conductivity<=100) %>%  
  select(PRECIP9120WS,TMAX9120WS,KFFACTWS,MSST2008,OMWS,CLAYWS,SWS,PCT_EROD,ELEVWS,SW_FLUXWS,POPDEN2010WS,NA2OWS,ROCKNWS,SANDWS,COMPSTRGTHWS,WTDEPWS,RDCRSWS,CAOWS,BFIWS,PCTDECID2001WS) %>% 
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_density() +
  geom_rug() + ggtitle("Conductivity 0-100")

# 100-300
cond_vars_selected %>%
  filter(Conductivity > 100 | Conductivity <= 300) %>% 
  select(PRECIP9120WS,TMAX9120WS,KFFACTWS,MSST2008,OMWS,CLAYWS,SWS,PCT_EROD,ELEVWS,SW_FLUXWS,POPDEN2010WS,NA2OWS,ROCKNWS,SANDWS,COMPSTRGTHWS,WTDEPWS,RDCRSWS,CAOWS,BFIWS,PCTDECID2001WS) %>% 
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_density() +
  geom_rug() + ggtitle("Conductivity 100-300")

# 300+
cond_vars_selected %>%
  filter(Conductivity > 300) %>% 
  select(PRECIP9120WS,TMAX9120WS,KFFACTWS,MSST2008,OMWS,CLAYWS,SWS,PCT_EROD,ELEVWS,SW_FLUXWS,POPDEN2010WS,NA2OWS,ROCKNWS,SANDWS,COMPSTRGTHWS,WTDEPWS,RDCRSWS,CAOWS,BFIWS,PCTDECID2001WS) %>% 
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_density() +
  geom_rug() + ggtitle("Conductivity >300")

# All TSS
cond_vars_selected %>%
  select(PRECIP9120WS,TMAX9120WS,KFFACTWS,MSST2008,OMWS,CLAYWS,SWS,PCT_EROD,ELEVWS,SW_FLUXWS,POPDEN2010WS,NA2OWS,ROCKNWS,SANDWS,COMPSTRGTHWS,WTDEPWS,RDCRSWS,CAOWS,BFIWS,PCTDECID2001WS) %>% 
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_density() +
  geom_rug() + ggtitle("All sites")

```

# **5 - RANDOM FOREST MODELS**

```{r}
# SUBSET DATA
cond.cal <- cond_vars_selected %>%  #subset CALibration dataset
  filter(cal_val == 'CAL') %>%  
  select(-c(MLocID:COMID, Conductivity)) #drop conductivity in favor of logCond. Drop AWQMS columns too.

cond.val <- cond_vars_selected %>%  #subset VALidation dataset
  filter(cal_val == 'VAL') %>%  
  select(-c(MLocID:COMID, Conductivity))

cond.ref <- cond_vars_selected %>% #subset reference only dataset
  filter(ReferenceSite == 'REFERENCE') %>%  
  select(-c(MLocID:COMID, Conductivity))

cond.cal_val <- rbind(cond.cal, cond.val)
#write_xlsx(cond.cal_val, path = paste0("C://Users//sberzin//OneDrive - Oregon//Desktop//Cond-Cal-val_New", Sys.Date(), ".xlsx"))
```

## FULL MODEL - ALL PREDICTORS INCLUDED (N = 79)

#### Tuning the model (finding best mtry)

```{r}
# One way to find best mtry based on tuneRF.
    # Tune mtry based on OOB error
# best_mtry <- tuneRF(cond.cal[, -which(names(cond.cal) == "logCond")], # Predictors
#                         cond.cal$logCond, # Response
#                         ntreeTry = 500, # Number of trees to try for each mtry
#                         stepFactor = 2, # Factor to multiply/divide mtry by
#                         improve = 0.01, # Minimum improvement to continue search
#                         trace = TRUE, # Print progress
#                         plot = TRUE) # Plot OOB error vs. mtry
# print(best_mtry)
# 
# # Another approach using Caret.  Takes >50 minutes to run, not that different from mtry approach above.
# control <- trainControl(method="repeatedcv", number=10,repeats = 3, search="random")
# set.seed(1)
# mtry <- sqrt(ncol(cond.cal[ , 2:74]
# ))
# rf_random <- train(logCond ~., data = cond.cal, method = "rf", metric = "RMSE", tuneLength = 15, trControl=control)
# print(rf_random)
# plot(rf_random)

```

#### Build full model

```{r}
set.seed(39)

rf.full <- randomForest(logCond ~ ., cond.cal, importance = TRUE, mtry=20, keep.forest = TRUE, ntree = 500) #run random forest model on all predictors. mtry=20 based on Caret grid search results.
print(rf.full)

varImpPlot(rf.full, type = 1, n.var = 25, main = "All-Sites Model") #variable importance plot
```

#### Tuning the model (how many trees)

```{r}
# How many trees is appropriate?
plot(rf.full, log="x", main = '')  # 500 seems to work fine.
```

#### Model prediction errors - full model

```{r}
# Predictions
pred.rf <- predict(rf.full, newdata = cond.cal)

# Model error 
full.rmse<- rmse(exp(pred.rf), exp(cond.cal$logCond))

range_cond <- max(exp(cond.cal_val$logCond)) - min(exp(cond.cal_val$logCond))
full.rmse_scaled <- full.rmse/range_cond

# Percent variance explained
rf.full_pct.var <- round(100 * rf.full$rsq[length(rf.full$rsq)], 2)

# Plot
plot(cond.cal$logCond ~ pred.rf, xlab = 'predicted logCond', ylab = 'observed logCond', main = 'Full model')
abline(a=0,b=1)
text(4,6, paste0("RMSE = ",round(full.rmse, 2)," | scaled RMSE = ", round(full.rmse_scaled*100,2), "%"))
text(4,5.5, paste0("Variance explained = ",rf.full_pct.var,"%"))
```
## REDUCED MODEL - IMPORTANT PREDICTORS ONLY

#### Build reduced model with 15 predictors

```{r}
set.seed(32)

rf.red_15 <- randomForest(logCond ~ PRECIP9120WS+TMAX9120WS+KFFACTWS+MSST2008+OMWS+CLAYWS+SWS+PCT_EROD+ELEVWS+SW_FLUXWS+POPDEN2010WS+NA2OWS+ROCKNWS+SANDWS+COMPSTRGTHWS, data = cond.cal, importance = TRUE,  keep.forest = TRUE, mtry=15, ntree = 500) 

print(rf.red_15)
summary(rf.red_15)

varImpPlot(rf.red_15, type = 1, n.var = 15, main = "Reduced Model Top 15") #variable importance plot

# Predictions
pred.rf.red_15 <- predict(rf.red_15, newdata = cond.cal)

# Model error 
red_15.rmse<- rmse(exp(pred.rf.red_15), exp(cond.cal$logCond))
red_15.rmse_scaled <- red_15.rmse/range_cond

# Percent variance explained
rf.red_15_pct.var <- round(100 * rf.red_15$rsq[length(rf.red_15$rsq)], 2)

# Plot
plot(cond.cal$logCond ~ pred.rf.red_15, xlab = 'predicted logCond', ylab = 'observed logCond', main = 'Reduced Model Top 15')
abline(a=0,b=1)
text(4,6, paste0("RMSE = ",round(red_15.rmse, 2)," | scaled RMSE = ", round(red_15.rmse_scaled*100,2), "%"))
text(4,5.5, paste0("Variance explained = ",rf.red_15_pct.var,"%"))
```
#### Build reduced model with 9 predictors

```{r}
set.seed(32)

rf.red_9 <- randomForest(logCond ~ PRECIP9120WS+TMAX9120WS+KFFACTWS+MSST2008+OMWS+CLAYWS+SWS+PCT_EROD+ELEVWS, data = cond.cal, importance = TRUE,  keep.forest = TRUE, mtry=9, ntree = 500) 

print(rf.red_9)
summary(rf.red_9)

varImpPlot(rf.red_9, type = 1, n.var = 9, main = "Reduced Model Top 9") #variable importance plot

# Predictions
pred.rf.red_9 <- predict(rf.red_9, newdata = cond.cal)

# Model error 
red_9.rmse<- rmse(exp(pred.rf.red_9), exp(cond.cal$logCond))
red_9.rmse_scaled <- red_9.rmse/range_cond

# Percent variance explained
rf.red_9_pct.var <- round(100 * rf.red_9$rsq[length(rf.red_9$rsq)], 2)

# Plot
plot(cond.cal$logCond ~ pred.rf.red_9, xlab = 'predicted logCond', ylab = 'observed logCond', main = 'Reduced Model Top 9')
abline(a=0,b=1)
text(4,6, paste0("RMSE = ",round(red_9.rmse, 2)," | scaled RMSE = ", round(red_9.rmse_scaled*100,2), "%"))
text(4,5.5, paste0("Variance explained = ",rf.red_9_pct.var,"%"))
```
#### Build reduced model with 5 predictors

```{r}
set.seed(32)

rf.red_5 <- randomForest(logCond ~ PRECIP9120WS+TMAX9120WS+KFFACTWS+MSST2008+OMWS, data = cond.cal, importance = TRUE,  keep.forest = TRUE, mtry=5, ntree = 500) 

print(rf.red_5)
summary(rf.red_5)

varImpPlot(rf.red_5, type = 1, n.var = 5, main = "Reduced Model Top 5") #variable importance plot

# Predictions
pred.rf.red_5 <- predict(rf.red_5, newdata = cond.cal)

# Model error 
red_5.rmse<- rmse(exp(pred.rf.red_5), exp(cond.cal$logCond))
red_5.rmse_scaled <- red_5.rmse/range_cond

# Percent variance explained
rf.red_5_pct.var <- round(100 * rf.red_5$rsq[length(rf.red_5$rsq)], 2)

# Plot
plot(cond.cal$logCond ~ pred.rf.red_5, xlab = 'predicted logCond', ylab = 'observed logCond', main = 'Reduced Model Top 5')
abline(a=0,b=1)
text(4,6, paste0("RMSE = ",round(red_5.rmse, 2)," | scaled RMSE = ", round(red_5.rmse_scaled*100,2), "%"))
text(4,5.5, paste0("Variance explained = ",rf.red_5_pct.var,"%"))
```


#### Build reduced model with 3 predictors

```{r}
set.seed(32)

rf.red_3 <- randomForest(logCond ~ PRECIP9120WS+TMAX9120WS+KFFACTWS, data = cond.cal, importance = TRUE,  keep.forest = TRUE, mtry=3, ntree = 500) 

print(rf.red_3)
summary(rf.red_3)

varImpPlot(rf.red_3, type = 1, n.var = 3, main = "Reduced Model Top 3") #variable importance plot

# Predictions
pred.rf.red_3 <- predict(rf.red_3, newdata = cond.cal)

# Model error 
red_3.rmse<- rmse(exp(pred.rf.red_3), exp(cond.cal$logCond))
red_3.rmse_scaled <- red_3.rmse/range_cond

# Percent variance explained
rf.red_3_pct.var <- round(100 * rf.red_3$rsq[length(rf.red_3$rsq)], 2)

# Plot
plot(cond.cal$logCond ~ pred.rf.red_3, xlab = 'predicted logCond', ylab = 'observed logCond', main = 'Reduced Model Top 3')
abline(a=0,b=1)
text(4,6, paste0("RMSE = ",round(red_3.rmse, 2)," | scaled RMSE = ", round(red_3.rmse_scaled*100,2), "%"))
text(4,5.5, paste0("Variance explained = ",rf.red_3_pct.var,"%"))

```
#### Residual plot for red_3 model

```{r}
residuals.red_3 <- exp(cond.cal$logCond) - exp(pred.rf.red_3) # Observed minus predicted 
plot(residuals.red_3 ~ exp(pred.rf.red_3), xlab = "Predicted Conductivity (uS/cm)", ylab = "Residuals", main="rf.red_3 residuals")
abline(h=0, col = "red", lty = 2)
```

#### Test reduced model with VAL data

```{r}
# Predictions
pred.rf.red_9_val <- predict(rf.red_9, newdata = cond.val)

# Model error 
red_9_val.rmse<- rmse(exp(pred.rf.red_9_val), exp(cond.val$logCond))
red_9_val.rmse_scaled <- red_9_val.rmse/range_cond

# Plot
plot(cond.val$logCond ~ pred.rf.red_9_val, xlab = 'predicted logCond', ylab = 'observed logCond', main = 'VALIDATION Reduced Model Top 9')
abline(a=0,b=1)
text(4.25,6, paste0("RMSE = ",round(red_9_val.rmse, 2)," | scaled RMSE = ", round(red_9_val.rmse_scaled*100,2), "%"))

#Untransformed plot no log scale axes
plot(exp(cond.val$logCond) ~ exp(pred.rf.red_9_val), xlab = 'predicted Conductivity', ylab = 'observed Conductivity', main = 'VALIDATION Reduced Model Top 9 untransformed')
abline(a=0,b=1)

#Untransformed plot no log scale axes
plot(exp(cond.val$logCond) ~ exp(pred.rf.red_9_val), log = 'xy', xlab = 'predicted Conductivity', ylab = 'observed Conductivity', main = 'VALIDATION Reduced Model Top 9 untransformed log scale axes')
abline(a=0,b=1)
```

```{r}
# Predictions
pred.rf.red_3_val <- predict(rf.red_3, newdata = cond.val)

# Model error 
red_3_val.rmse<- rmse(exp(pred.rf.red_3_val), exp(cond.val$logCond))
red_3_val.rmse_scaled <- red_3_val.rmse/range_cond

# Plot
plot(cond.val$logCond ~ pred.rf.red_3_val, xlab = 'predicted logCond', ylab = 'observed logCond', main = 'VALIDATION Reduced Model Top 3')
abline(a=0,b=1)
text(4.25,6, paste0("RMSE = ",round(red_3_val.rmse, 2)," | scaled RMSE = ", round(red_3_val.rmse_scaled*100,2), "%"))

#Untransformed plot no log scale axes
plot(exp(cond.val$logCond) ~ exp(pred.rf.red_3_val), xlab = 'predicted Conductivity', ylab = 'observed Conductivity', main = 'VALIDATION Reduced Model Top 9 untransformed')
abline(a=0,b=1)
text(150,600, paste0("RMSE = ",round(red_3_val.rmse, 2)," | scaled RMSE = ", round(red_3_val.rmse_scaled*100,2), "%"))

#Untransformed plot no log scale axes
plot(exp(cond.val$logCond) ~ exp(pred.rf.red_3_val), log = 'xy', xlab = 'predicted Conductivity', ylab = 'observed Conductivity', main = 'VALIDATION Reduced Model Top 3 untransformed log scale axes')
abline(a=0,b=1)
text(60,500, paste0("RMSE = ",round(red_3_val.rmse, 2)," | scaled RMSE = ", round(red_3_val.rmse_scaled*100,2), "%"))
```

#### Plot Obs vs pred CAL and VAL all sites

```{r}
# plot obs vs. predicted CAL 
par(mfrow=c(1,2))
par(mar=c(4.3,5,1,1))
plot(x = exp(pred.rf.red_3), y = exp(cond.cal$logCond),
	  xlab='Predicted Conductivity (μS/cm)', ylab='Observed Conductivity (μS/cm)', main='red_3 CAL', lwd=1.5, 
	  cex.lab=1.5, las = 1, font = 2)
abline(a=0, b=1, col='blue', lty=2) 

# plot obs vs. predicted VAL
par(new=TRUE)
plot(x = exp(pred.rf.red_3_val), y = exp(cond.val$logCond),
	  xlab='', ylab='', main='', pch=2, col='red', cex=1.3, lwd=1.5,axes=FALSE) 
 
# plot residuals CAL
par(mar=c(4.3,4.3,1,1))
plot(x = (exp(pred.rf.red_3)-1), y = exp(cond.cal$logCond)-exp(pred.rf.red_3),
	  xlab='Predicted Conductivity (μS/cm)', ylab='Residuals (obs-pred)', main='red_3 VAL', 
	  lwd=1.5,cex.lab=1.5, las = 1, font = 2)
abline(h=0, col="blue", lty = 2)
 
# plot residuals VAL
par(new=TRUE)	
plot(x = (exp(pred.rf.red_3_val)), y = exp(cond.val$logCond)-exp(pred.rf.red_3_val),
	  xlab='', ylab="", main="", 
	  pch=2, col='red', 
	  lwd=1.5,cex.lab=1.5, las = 1, font = 2, cex=1.3,
	  axes=FALSE)
```
Predictions on CAL + VAL
```{r}
# Predictions
pred.rf.red_3_cal_val <- predict(rf.red_3, newdata = cond.cal_val)

# Plot
plot(cond.cal_val$logCond ~ pred.rf.red_3_cal_val, xlab = 'predicted logCond', ylab = 'observed logCond', main = 'CAL & VAL Reduced Model Top 3')
abline(a=0,b=1)

#Untransformed plot no log scale axes
plot(exp(cond.cal_val$logCond) ~ exp(pred.rf.red_3_cal_val), xlab = 'predicted Conductivity', ylab = 'observed Conductivity', main = 'CAL & VAL Reduced Model Top 3 untransformed')
abline(a=0,b=1)

#Untransformed plot no log scale axes
plot(exp(cond.cal_val$logCond) ~ exp(pred.rf.red_3_cal_val), log = 'xy', xlab = 'predicted Conductivity', ylab = 'observed Conductivity', main = 'CAL & VAL Reduced Model Top 3 untransformed log scale axes')
abline(a=0,b=1)

# CALCULATE PROPORTIONS ABOVE 1:1 AND 2:1 LINES
oe <- cbind(pred.rf.red_3_cal_val, cond.cal_val$logCond)
oe <- as.data.frame(oe) %>% 
  rename(pred_logCond = V2) %>% 
  mutate(obs_Cond = exp(cond.cal_val$logCond)) %>% 
  mutate(pred_Cond = exp(pred.rf.red_3_cal_val)) %>% 
  mutate('O/E' = obs_Cond/pred_Cond)

print(sum(oe$`O/E`>1)/nrow(cond.cal_val)) # prop above 1:1 line
print(sum(oe$`O/E`>2)/nrow(cond.cal_val)) # prop above 2:1 line
```

