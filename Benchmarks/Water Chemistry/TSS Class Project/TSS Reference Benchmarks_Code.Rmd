---
title: "TSS Reference Benchmarks"
author: "S. Berzins, A. Thompson"
date: "2025-10-21"
output: html_document
---

#### **PREFACE:** This script explores the creation of a site-specific reference benchmark for total suspended solids (TSS) for ESM 566 Fall Environmental Statistics final project.

# **1 - LOAD PACKAGES**

```{r}
library(AWQMSdata) #visit 'https://github.com/TravisPritchardODEQ/AWQMSdata' for installation instructions
library(StreamCatTools) #visit 'https://github.com/USEPA/StreamCatTools' for installation instructions
library(tidyverse)
library(readxl)
```

# **2 - IMPORT DATA**

## STATIONS - *FROM DEQ STATIONS DATABASE*

#### Pull all sites with a reference status designation

```{r}
stations <- query_stations()
ref_stations <- stations %>% 
  filter(ReferenceSite %in% c("REFERENCE" , "MODERATELY DISTURBED", "MOST DISTURBED")) %>% 
  select(MLocID, COMID, ReferenceSite, OrgID)
rm(stations)
```

## WATER CHEMISTRY DATA - *FROM AWQMS*

#### Total suspended solids (TSS) data for sites with a reference status designation

```{r}
tss <- AWQMS_Data(MLocID = ref_stations$MLocID, Char_Name = 'Total suspended solids')
```

#### Merge AWQMS and Stations data into single dataframe

```{r}
tss.all <- inner_join(tss, ref_stations, by = "MLocID")
```

## WATERSHED METRICS - *FROM EPA STREAMCAT*

#### Can search for predictors of interest here: <https://www.epa.gov/national-aquatic-resource-surveys/streamcat-metrics-and-definitions>

# do correlation analysis for streamcat predictors - which covary with each other? Get all predictors for watersheds. 
# need to query catchment data when we "Used closest COMID"

```{r}
comids <- read_excel("TSS_COMIDs.xlsx") #output file from ref benchmarks script

scaoi <-StreamCatTools::sc_get_params(param = 'aoi') #make list of all sc aois
print(paste0('Area of interest available parameters are: ', paste(scaoi, collapse = ', ')))

scpar <- StreamCatTools::sc_get_params(param = 'metric_names') #make list of all sc metrics
print(paste0('Parameters names are: ', paste(scpar, collapse = ', ')))


comids_split <- split(comids2, ceiling(seq_along(comids2)/750)) #this isn't really splitting them into chunks of 750 ???
metrics_split <- split(scpar, ceiling(seq_along(scpar)/750)) #seems to work, as now have two lists, first one cutting off at 750

streamcat <- purrr::map_dfr(comids_split, ~StreamCatTools::sc_get_data(comid = .,
                                                                           metric = "all",
                                                                           showAreaSqKm = TRUE,
                                                                           aoi='catchment,watershed,other'))


# single comid, all metrics, one aoi (can't handle all metrics and all aois)
test <- StreamCatTools::sc_get_data(comid = '23648454', metric = 'pctow2001', showAreaSqKm = TRUE, aoi='ws, cat')



comids <- read_excel("TSS_COMIDs.xlsx") #output file from ref benchmarks script
scaoi <-StreamCatTools::sc_get_params(param = 'aoi') #make list of all sc aois


myfunction <- function(comids, scaoi) {


streamcat <- purrr::map_dfr(comids, scaoi, ~StreamCatTools::sc_get_data(comid = comids,
                                                                          metric = 'all',
                                                                          showAreaSqKm = TRUE,
                                                                          aoi = scaoi))
return(streamcat)
}

doit <- myfunction(comids = comids, scaoi = scaoi)


#````````````````````````for loops

for (i in comids) {
ws <- StreamCatTools::sc_get_data(i, metric = 'all', showAreaSqKm = TRUE, aoi='watershed')
}

for (i in comids) {
ca <- StreamCatTools::sc_get_data(i, metric = 'all', showAreaSqKm = TRUE, aoi='catchment')
}

for (i in comids) {
ot <- StreamCatTools::sc_get_data(i, metric = 'all', showAreaSqKm = TRUE, aoi='other') #times out for 'other' aoi
}

allmets <- left_join(ws, ca, by = "comid") #join catchment and watershed


core <- cor(allmets, method = "spearman")
corews <- cor(ws, method = "spearman")

look <- which(abs(corews) > .80 & abs(corews) < 1, arr.ind = T)



#export full correl table into excel. conditional format >0.8, sort out.
#lots of temp data highly correlated, decide which metric to use
look <- corews[corews < abs(0.8) | corews == 1] <- ""
look <- filter(core, array > abs(0.8))
look <- filter_all(any_vars(abs(.) > 0.8))

look <- core %>% 
  select_if(is.numeric) %>% 
  cor() %>% 
  round(digits = 2) %>% 
  as.data.frame() %>%
  select_if(funs(all(abs(.) > 0.8)))

```

```{r}

usablemetrics <- subset full list of metrics by USE ==  "YES"

if(type == "immutable area"){
    


    streamcat <- purrr::map_dfr(comids_split, ~StreamCatTools::sc_get_data(.,
                                                                           metric = 'TMAX8110,BFI,ELEV,clay,precip8110,mwst2008,mwst2009,mwst2013,mwst2014', 
                                                                           showAreaSqKm = TRUE,
                                                                           aoi='catchment,watershed,other'))
    
  }
  
  if(type == "disturbance wildfire"){
```





```{r}
#Get list of COMIDs 
comids <- unique(tss.all$COMID)

#Remove blanks
comids <- comids[!is.na(comids)]

#Run function
get_streamcat <- function(comids){
  
comid_narm <- na.omit(comids)
comids_split <- split(comid_narm, ceiling(seq_along(comids)/650))

streamcat <- purrr::map_dfr(comids_split, ~StreamCatTools::sc_get_data(comid = .,
                                                                           metric = 'pctcrop2019',
                                                                           showAreaSqKm = TRUE,
                                                                           aoi='catchment,watershed,other'))

streamcat <- get_streamcat(comids = comids)

names(streamcat) <- base::toupper(names(streamcat))

return(streamcat)
}

streamcat <- get_streamcat(comids = comids)
```


